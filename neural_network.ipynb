{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIHnQikZC+j/EFyfVpEQ0B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-Tos1wa/pytorch/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção de uma rede neural"
      ],
      "metadata": {
        "id": "wJecnoijZhji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yJUYxWAg5Msk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn #oferece todos os pacotes necessários para construir uma rede neural\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #verifica se GPU está disponível, caso contrário utiliza cpu\n",
        "print(f\"Using {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdZFK6KK-0dR",
        "outputId": "d3c33139-746a-433c-9b2e-6df398675e7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição da rede neural e inicializa as camadas em __init__\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "#Neste método é implementado as operaçÕes nos dados de entrada\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "l8EIxadN_hvS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instancia a classe, coloca no 'device' e printa a sua estrutura\n",
        "n_network = NeuralNetwork().to(device)\n",
        "print(n_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwwfW30kBeX4",
        "outputId": "35e75ea8-2481-4068-956b-09729c3981dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = torch.rand(2, 28, 28, device = device)\n",
        "logits = n_network(example)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "prediction = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i_b37LrCNK_",
        "outputId": "070e2006-a40c-4803-b9b5-824401832511"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([4, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "obs: Passing input data on the model will return a 2D tensor with dim = 0 corresponding to each output of 10 raw predicted values for each class, and dim = 1 corresponds to the individual values of each output. The prediction probability is shown by passing it through an instance of the nn.Softmax module."
      ],
      "metadata": {
        "id": "m3EyHyukEQNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "w_yj7ipjYh9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento de uma rede neural"
      ],
      "metadata": {
        "id": "xu50BtA4Zegp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "3jzMUmVVDscY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estabelece conexão com o arquivo de dados MNIST e faz requests por tais dados\n",
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH/\"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "url = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
        "filename = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH/filename).exists():\n",
        "  content = requests.get(url + filename).content\n",
        "  (PATH/filename).open(\"wb\").write(content)\n",
        "\n",
        "# Dataset está armazenado em formato numpy array e usando pickle (formato específico Python p/ dados serializados)\n",
        "with gzip.open((PATH/filename).as_posix(), \"rb\") as f:\n",
        "  ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding = \"latin-1\")\n",
        "\n",
        "# Cada imagem está armazenada como um linha de comprimento 784 (o tamanho de cd imagem é 28x28).\n",
        "# Para poder visualizar, primeiro transforma-a em 2D.\n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "try:\n",
        "  import google.colab\n",
        "except ImportError:\n",
        "  pyplot.show()\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "LWivjwYSZFzz",
        "outputId": "69c5b9b4-0b2f-4ec3-bff6-6d6679f054ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "AU2GSh62d5ze"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforma o dataset em torch.tensor, que é a \"unidade básica\"do Pytorch\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")\n",
        "n, c = x_train.shape\n",
        "print(f\"x_train: {x_train}\")\n",
        "print(f\"y_train: {y_train}\")\n",
        "print(f\"formato de x_train: {n, c}\")\n",
        "print(y_train.min(), y_train.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ScxbJs-e42Q",
        "outputId": "f8e0ad0d-ebfd-42bf-ed5a-17bc7076a750"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "y_train: tensor([5, 0, 4,  ..., 8, 4, 8])\n",
            "formato de x_train: (50000, 784)\n",
            "tensor(0) tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<https://pytorch.org/tutorials/beginner/nn_tutorial.html>"
      ],
      "metadata": {
        "id": "XBtk7i54G_US"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso dos módulos e classes de <code>torch.nn.functional</code>"
      ],
      "metadata": {
        "id": "83xOzlEmLEcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sem <code>torch.nn</code>"
      ],
      "metadata": {
        "id": "3pA9prAeKnDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "mhKnfiBH7Xwr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pesos são inicializados como números aleatórios multiplcados por 1/sqrt(n)\n",
        "# Bias inicializados como tensor de 0 e então coloca-se um gradiente p/ ser calculado durante backpropagation\n",
        "weights = torch.randn(784, 10)/math.sqrt(784)\n",
        "weights.requires_grad_() # _ significa que a operação é feita \"in-place\"\n",
        "bias = torch.zeros(10, requires_grad = True)"
      ],
      "metadata": {
        "id": "l4uNg1_d7iXb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "  return log_softmax(xb @ weights + bias) # '@' => simboliza multiplicação de matrizes"
      ],
      "metadata": {
        "id": "P_-BUqdq748g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 64\n",
        "xb = x_train[0:batch]\n",
        "pred = model(xb)\n",
        "pred[0], pred.shape\n",
        "print(f\"Tensor inicial: {pred[0]} \\n Formato: {pred.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyZLuO01_bMv",
        "outputId": "93b5ec9a-dc64-4a52-c74b-b923f7056f75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor inicial: tensor([-2.2408, -3.1888, -2.3421, -2.8364, -2.3449, -2.1744, -2.7663, -1.7999,\n",
            "        -1.8081, -2.3441], grad_fn=<SelectBackward0>) \n",
            " Formato: torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de custo/perda\n",
        "def nll(input, target):\n",
        "  return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll\n",
        "\n",
        "yb = y_train[0:batch]\n",
        "print(loss_func(pred, yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPg_gUG8AABg",
        "outputId": "ae77be01-3929-42ca-baa4-3797163577a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4219, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cálculo da precisão do modelo\n",
        "def acc(out, yb):\n",
        "  preds = torch.argmax(out, dim=1)\n",
        "  return (preds == yb).float().mean()\n",
        "\n",
        "#print(f\"Exatidão: {acc(pred, yb)}\")\n",
        "print(acc(pred, yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARVxJ_SQA7L6",
        "outputId": "0e8ac096-8494-4372-86c6-b4dfac0b6ac1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0469)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de um training loop\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "learning_rate = 0.5\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n-1) // batch + 1):\n",
        "    start_i = i * batch\n",
        "    end_i = start_i + batch\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      weights -= weights.grad * learning_rate\n",
        "      bias -= bias.grad * learning_rate\n",
        "      weights.grad.zero_()\n",
        "      bias.grad.zero_()"
      ],
      "metadata": {
        "id": "veaoamQjCAsW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradientes são usados para atualizar os pesos e bias. E essas ações não serão gravadas no próximo cálculo do gradiente, já que <code>torch.no_grad()</code>.\n",
        "Depois, faz-se com que o gradiente retorne a ser um tensor composto por 0.\n",
        "\n",
        "obs: Este é um **modelo de regressão logística**."
      ],
      "metadata": {
        "id": "cr9gf0BGIVkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Função de perda: {loss_func(model(xb), yb)} \\n Exatidão: {acc(model(xb), yb)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0if_20cEdjg",
        "outputId": "4bf2d9c0-def9-41df-f6b2-5af23697982e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Função de perda: 0.0805879533290863 \n",
            " Exatidão: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Com <code>torch.nn</code>"
      ],
      "metadata": {
        "id": "sKDlENn5LdJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "7jMmkIJAKRlH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "  return xb @ weights + bias"
      ],
      "metadata": {
        "id": "ayUaJ1DBMUFY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(f\"Função de perda: {loss_func(model(xb), yb)} \\n Exatidão: {acc(model(xb), yb)}\")\n",
        "print(loss_func(model(xb), yb), acc(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnYg6jmtMhNe",
        "outputId": "4f2c5a1f-e0e9-4641-b984-602095aa9f75"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0806, grad_fn=<NllLossBackward0>) tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "R0lgj-ZuMqLp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mnist_Logistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "    self.bias = nn.Parameter(torch.zeros(10))\n",
        "  def forward(self, xb):\n",
        "    return xb @ self.weights + self.bias\n",
        "\n",
        "model = Mnist_Logistic()"
      ],
      "metadata": {
        "id": "WoQnQWlvN78a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "obs: Cria-se uma classe usando a subclasse <code>nn.Module</code> contendo todos os parâmetros que serão usados no treinamento dos loops."
      ],
      "metadata": {
        "id": "DQAelL5GPDMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m958aQy3Opmx",
        "outputId": "a8f12dda-e118-4c5d-d44b-06c8e4c5b7ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3027, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#epochs = 3\n",
        "def train_loop():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n - 1) // batch + 1):\n",
        "      start = i * batch\n",
        "      end = start + batch\n",
        "      xb = x_train[start:end]\n",
        "      yb = y_train[start:end]\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * learning_rate\n",
        "        model.zero_grad()\n",
        "\n",
        "train_loop()"
      ],
      "metadata": {
        "id": "iO3fdtiLOwuQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com <code>torch.no_grad()</code>  e <code>model.parameters</code> não é preciso atualizar os parâmetors manualmente, tornando o treino mais conciso e com menos propensão ao erro."
      ],
      "metadata": {
        "id": "16cWed9QRLWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6a-E1XTQlN9",
        "outputId": "5603add9-3d65-4155-eeda-4542e7644315"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0825, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Mnist_Logistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linnear = nn.Linear(784, 10)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    return self.linnear(xb)\n",
        "\n",
        "model_refac = Mnist_Logistic()"
      ],
      "metadata": {
        "id": "ywH2d8C8QteL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refatora-se o código usando uma classe do Pytorch <code>nn.Linear</code>, que define e inicializa as variáveis, pesos e bias e calcula a função forward. Isso simplifica o algoritmo e \"acelera\" o processo."
      ],
      "metadata": {
        "id": "7bY_A8uPry25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXiEyGfrryDY",
        "outputId": "554a3327-7b36-4510-92db-242f3ed67863"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0825, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop()\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmS3H5Sas4-p",
        "outputId": "8708f1b0-f19f-44b5-d14a-5a72dcef0f61"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0661, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "u8I1uKiKtFb6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso do passo \"step\" do optimizer para atualizar cada parâmetro automaticamente\n",
        "def get_model():\n",
        "  model_optim = model_refac\n",
        "  return model_optim, optim.SGD(model_optim.parameters(), lr = learning_rate)\n",
        "\n",
        "model_optim, opt = get_model()\n",
        "print(loss_func(model_optim(xb), yb))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n - 1) // batch + 1):\n",
        "    start = i * batch\n",
        "    end = start + batch\n",
        "    xb = x_train[start:end]\n",
        "    yb = y_train[start:end]\n",
        "    pred = model_optim(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(loss_func(model_optim(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW4wG1NwyXUw",
        "outputId": "f68a70a3-5fee-4769-8856-499fa81cab98"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3292, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0815, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Usando Dataset"
      ],
      "metadata": {
        "id": "jyysJ2bwnc7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "metadata": {
        "id": "D6sFmD_jz6dU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<code>TensorDataset</code> é uma classe do Dataset e ele envolve tensores, facilitando na hora de iterar, indexar e dividir em pedaços (slice) as variáveis independentes e dependentes de treino."
      ],
      "metadata": {
        "id": "4jzMl9ImCpIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "\n",
        "\"\"\"em vez de\n",
        "xb = x_train[start:end]\n",
        "yb = y_train[start:end]\"\"\"\n",
        "\n",
        "xb, yb = train_ds[i*batch:i*batch+batch]"
      ],
      "metadata": {
        "id": "_0gi4EzXCVoy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_optim, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n - 1)//batch + 1):\n",
        "    xb, yb\n",
        "    pred = model_optim(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(loss_func(model_optim(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdeAjf81CdNo",
        "outputId": "49808215-e8e4-4c1b-dbf4-b5f6809b0086"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0004, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Usando DataLoader"
      ],
      "metadata": {
        "id": "4ILlvq0_nkUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "3VNuH5TZGeuE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<code>DataLoader</code> gerencia batches. Ao criar um DataLoader de um Dataset, é mais fácil iterar batches e nos traz cada minibatch automaticamente."
      ],
      "metadata": {
        "id": "FFdffI0KoAK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size = batch)"
      ],
      "metadata": {
        "id": "p3aQsbPMntZG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_optim, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for xb, yb in train_dl:\n",
        "    pred = model_optim(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(loss_func(model_optim(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCp94pMOn-2b",
        "outputId": "a16a81a9-2d00-478f-8413-f66814644bad"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0434, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validação\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size = batch, shuffle = True)\n",
        "\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = batch*2)"
      ],
      "metadata": {
        "id": "zSf8YkuspCKp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_optim, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_optim.train()\n",
        "  for xb, yb in train_dl:\n",
        "    pred = model_optim(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "  model_optim.eval()\n",
        "  with torch.no_grad():\n",
        "    valid_loss = sum(loss_func(model_optim(xb), yb) for xb, yb in valid_dl)\n",
        "\n",
        "  print(epoch, valid_loss / len(valid_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1cIgTCxrLIS",
        "outputId": "af94399e-6aca-499a-d4df-698538151ba1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor(0.2822)\n",
            "1 tensor(0.3259)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zA3r89lr_eY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}